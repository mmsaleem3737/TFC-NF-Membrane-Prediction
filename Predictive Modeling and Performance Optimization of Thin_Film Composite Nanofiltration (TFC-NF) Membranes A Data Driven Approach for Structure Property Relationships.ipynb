{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6c93a2ca-36f5-4762-9d79-a587b76c8e1e",
   "metadata": {},
   "source": [
    "# Step 1: Load the Dataset\n",
    "\n",
    "**Description:**  \n",
    "Load the dataset from the Excel file **\"TFC_NF_membrane_data.xlsx\"** and display the first five rows.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d6668bfc-4404-4dde-ac37-3f0b316f2287",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 5 rows of the dataset:\n",
      "          Type  Size (nm)      Shape  Pore size (Ǻ)  Bond-ing*    Char-ge  \\\n",
      "0          NaN        NaN        NaN            NaN        NaN  (+, -, 0)   \n",
      "1  NaA zeolite      100.0  Spherical            4.0        0.0          -   \n",
      "2  NaA zeolite      100.0  Spherical            4.0        0.0          -   \n",
      "3  NaA zeolite      100.0  Spherical            4.0        0.0          -   \n",
      "4  NaA zeolite      100.0  Spherical            4.0        0.0          -   \n",
      "\n",
      "  Phase**,  Loading     RR    RCA        CWP  CSP    RWP    RSP  \n",
      "0  A or O       NaN    NaN    NaN  (LMH/bar)  (%)    NaN    NaN  \n",
      "1        A  0.00004  1.015  0.903      0.767  6.5  1.023  0.892  \n",
      "2        A  0.00010  0.956  0.857      0.767  6.5  1.174  0.908  \n",
      "3        A  0.00040  0.931  0.824      0.767  6.5  1.343  0.892  \n",
      "4        A  0.00100  0.952  0.713      0.767  6.5  1.488  0.969  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Loaded the dataset from  Excel file \n",
    "file_path = \"TFC_NF_membrane_data.xlsx\"\n",
    "df = pd.read_excel(file_path)\n",
    "\n",
    "# Displaying the first 5 rows of the dataset\n",
    "print(\"First 5 rows of the dataset:\")\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0941e15-88c3-4c71-aa23-0a98f0bc315a",
   "metadata": {},
   "source": [
    "# Step 2: Inspect the Data\n",
    "\n",
    "**Description:**  \n",
    "Examine the dataset's structure, data types, and missing values.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0bf49b98-12c0-4c58-ad74-97f8f7ddb2dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 189 entries, 0 to 188\n",
      "Data columns (total 14 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   Type           188 non-null    object \n",
      " 1   Size (nm)      188 non-null    float64\n",
      " 2   Shape          188 non-null    object \n",
      " 3   Pore size (Ǻ)  188 non-null    float64\n",
      " 4   Bond-ing*      188 non-null    float64\n",
      " 5   Char-ge        189 non-null    object \n",
      " 6   Phase**,       189 non-null    object \n",
      " 7   Loading        188 non-null    float64\n",
      " 8   RR             78 non-null     float64\n",
      " 9   RCA            134 non-null    float64\n",
      " 10  CWP            189 non-null    object \n",
      " 11  CSP            189 non-null    object \n",
      " 12  RWP            188 non-null    float64\n",
      " 13  RSP            188 non-null    float64\n",
      "dtypes: float64(8), object(6)\n",
      "memory usage: 20.8+ KB\n",
      "\n",
      "Missing Values per Column:\n",
      "Type               1\n",
      "Size (nm)          1\n",
      "Shape              1\n",
      "Pore size (Ǻ)      1\n",
      "Bond-ing*          1\n",
      "Char-ge            0\n",
      "Phase**,           0\n",
      "Loading            1\n",
      "RR               111\n",
      "RCA               55\n",
      "CWP                0\n",
      "CSP                0\n",
      "RWP                1\n",
      "RSP                1\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Step 2: Inspect the Data\n",
    "print(\"Dataset Info:\")\n",
    "df.info()\n",
    "\n",
    "print(\"\\nMissing Values per Column:\")\n",
    "print(df.isnull().sum())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a14170e1-5cd6-44f2-b0df-d45627f02f64",
   "metadata": {},
   "source": [
    "# Step 3: Cleaning Column Names and Converting Target Columns\n",
    "\n",
    "**Description:**  \n",
    "Cleaning the column names by removing unwanted characters and spaces, then convert the target columns **CWP** and **CSP** from object to numeric type.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3ae5056a-0c3f-4d53-a0a3-0537f1668482",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned Column Names:\n",
      "Index(['Type', 'Size (nm)', 'Shape', 'Pore size (Ǻ)', 'Bond-ing*', 'Char-ge',\n",
      "       'Phase**,', 'Loading', 'RR', 'RCA', 'CWP', 'CSP', 'RWP', 'RSP'],\n",
      "      dtype='object')\n",
      "\n",
      "Data Types for CWP and CSP after conversion:\n",
      "CWP    float64\n",
      "CSP    float64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Step 3: Cleaning Column Names\n",
    "df.columns = df.columns.str.strip().str.replace('[^a-zA-Z0-9_]', '_').str.replace('__', '_')\n",
    "print(\"Cleaned Column Names:\")\n",
    "print(df.columns)\n",
    "\n",
    "# Converting target columns CWP and CSP to numeric (force errors to NaN)\n",
    "df['CWP'] = pd.to_numeric(df['CWP'], errors='coerce')\n",
    "df['CSP'] = pd.to_numeric(df['CSP'], errors='coerce')\n",
    "\n",
    "# Checking conversion by printing data types of CWP and CSP\n",
    "print(\"\\nData Types for CWP and CSP after conversion:\")\n",
    "print(df[['CWP', 'CSP']].dtypes)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3ab5943-32d4-4c59-9d42-bfedf5405600",
   "metadata": {},
   "source": [
    "# Step 4: Impute Missing Values for Small Gaps\n",
    "\n",
    "**Description:**  \n",
    "For columns with only a few missing values (e.g., **Size (nm)**, **Pore size (Ǻ)**, **Bond-ing***, **Loading**, **RWP**, and **RSP**), imputing the missing values using the median strategy.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "1e4d2154-4af2-413b-ba2f-6275bed80c00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values after imputing small gaps:\n",
      "Type             0\n",
      "Size (nm)        0\n",
      "Shape            0\n",
      "Pore size (Ǻ)    0\n",
      "Bond-ing*        0\n",
      "Char-ge          0\n",
      "Phase**,         0\n",
      "Loading          0\n",
      "RR               0\n",
      "RCA              0\n",
      "CWP              0\n",
      "CSP              0\n",
      "RWP              0\n",
      "RSP              0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Defining the columns with small missing gaps\n",
    "small_gap_cols = ['Size (nm)', 'Pore size (Ǻ)', 'Bond-ing*', 'Loading', 'RWP', 'RSP']\n",
    "\n",
    "# Initialize the imputer with median strategy\n",
    "imputer = SimpleImputer(strategy='median')\n",
    "\n",
    "# Impute the missing values for these columns\n",
    "df[small_gap_cols] = imputer.fit_transform(df[small_gap_cols])\n",
    "\n",
    "# Checking missing values after imputation\n",
    "print(\"Missing values after imputing small gaps:\")\n",
    "print(df.isnull().sum())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79faa63f-1794-4a37-b137-aeeade3a7c47",
   "metadata": {},
   "source": [
    "# Step 5: Fill Missing Values for Categorical Columns\n",
    "\n",
    "**Description:**  \n",
    "Filling in missing values for the categorical columns **Type** and **Shape** using the mode (most frequent value).\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "53350878-5f11-4009-a4cc-a8f8155b9fa5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values after filling Type and Shape:\n",
      "Type             0\n",
      "Size (nm)        0\n",
      "Shape            0\n",
      "Pore size (Ǻ)    0\n",
      "Bond-ing*        0\n",
      "Char-ge          0\n",
      "Phase**,         0\n",
      "Loading          0\n",
      "RR               0\n",
      "RCA              0\n",
      "CWP              0\n",
      "CSP              0\n",
      "RWP              0\n",
      "RSP              0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Step 5: Filling missing values in categorical columns\n",
    "df['Type'] = df['Type'].fillna(df['Type'].mode()[0])\n",
    "df['Shape'] = df['Shape'].fillna(df['Shape'].mode()[0])\n",
    "\n",
    "# Checking missing values after filling Type and Shape\n",
    "print(\"Missing values after filling Type and Shape:\")\n",
    "print(df.isnull().sum())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db35f8ce-ab83-4423-b864-8a2ff859357c",
   "metadata": {},
   "source": [
    " # Step 6: Impute Missing Values in Target Columns (CWP and CSP)\n",
    "\n",
    "**Description:**  \n",
    "Impute any missing values in the target columns **CWP** and **CSP** using the median value.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "6fb83e91-3dad-42d0-aacb-134aa4721b49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values after imputing CWP and CSP:\n",
      "Type             0\n",
      "Size (nm)        0\n",
      "Shape            0\n",
      "Pore size (Ǻ)    0\n",
      "Bond-ing*        0\n",
      "Char-ge          0\n",
      "Phase**,         0\n",
      "Loading          0\n",
      "RR               0\n",
      "RCA              0\n",
      "CWP              0\n",
      "CSP              0\n",
      "RWP              0\n",
      "RSP              0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Step 6: Imputeing Missing Values for Target Columns (CWP and CSP)\n",
    "df['CWP'] = df['CWP'].fillna(df['CWP'].median())\n",
    "df['CSP'] = df['CSP'].fillna(df['CSP'].median())\n",
    "\n",
    "# Checking missing values after imputing CWP and CSP\n",
    "print(\"Missing values after imputing CWP and CSP:\")\n",
    "print(df.isnull().sum())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d01e465-2d52-4e7a-9a74-c5f752c02058",
   "metadata": {},
   "source": [
    " # Step 7: Imputing Missing Values for Large Gaps (RR and RCA)\n",
    "\n",
    "**Description:**  \n",
    "Using predictive imputation with a Linear Regression model to fill missing values:\n",
    "- First, impute **RR** using available numerical features.\n",
    "- Then, impute **RCA** using the same features (including the now-complete **RR**).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6b2c60b4-9184-4c5e-8442-147c9d1ba41e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values after imputing RR:\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Step 7a: Impute missing values in \"RR\"\n",
    "# Separate rows where RR is not missing\n",
    "rr_not_null = df[df['RR'].notnull()]\n",
    "rr_null = df[df['RR'].isnull()]\n",
    "\n",
    "# Define features to use for predicting RR\n",
    "features_for_rr = ['Size (nm)', 'Pore size (Ǻ)', 'Bond-ing*', 'Loading', 'RWP', 'RSP', 'CWP', 'CSP']\n",
    "\n",
    "# Train a Linear Regression model on the rows with available RR\n",
    "rr_model = LinearRegression()\n",
    "rr_model.fit(rr_not_null[features_for_rr], rr_not_null['RR'])\n",
    "\n",
    "# Predict missing RR values\n",
    "predicted_rr = rr_model.predict(rr_null[features_for_rr])\n",
    "\n",
    "# Fill the missing RR values with the predictions\n",
    "df.loc[df['RR'].isnull(), 'RR'] = predicted_rr\n",
    "\n",
    "# Check missing values for RR\n",
    "print(\"Missing values after imputing RR:\")\n",
    "print(df['RR'].isnull().sum())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d3b7db7-b4d6-4ed7-89b2-8d129561a8c0",
   "metadata": {},
   "source": [
    "### Step 7b: Impute Missing Values for RCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d402a965-b33f-4f4d-9e68-195395d423a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values after imputing RCA:\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "# Step 7b: Impute missing values in \"RCA\"\n",
    "# Separate rows where RCA is not missing and where it is missing\n",
    "rca_not_null = df[df['RCA'].notnull()]\n",
    "rca_null = df[df['RCA'].isnull()]\n",
    "\n",
    "# Define features to use for predicting RCA (include RR since it's now complete)\n",
    "features_for_rca = ['Size (nm)', 'Pore size (Ǻ)', 'Bond-ing*', 'Loading', 'RWP', 'RSP', 'CWP', 'CSP', 'RR']\n",
    "\n",
    "# Train a Linear Regression model on the rows with available RCA\n",
    "rca_model = LinearRegression()\n",
    "rca_model.fit(rca_not_null[features_for_rca], rca_not_null['RCA'])\n",
    "\n",
    "# Predict missing RCA values\n",
    "predicted_rca = rca_model.predict(rca_null[features_for_rca])\n",
    "\n",
    "# Fill the missing RCA values with the predictions\n",
    "df.loc[df['RCA'].isnull(), 'RCA'] = predicted_rca\n",
    "\n",
    "# Check missing values for RCA\n",
    "print(\"Missing values after imputing RCA:\")\n",
    "print(df['RCA'].isnull().sum())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ec7a005-4806-46c6-ab6d-675ad32df2cf",
   "metadata": {},
   "source": [
    " # Step 8: Encoding Categorical Variables\n",
    "\n",
    "**Description:**  \n",
    "Standardize and encode the categorical columns:\n",
    "- **Char-ge:** Convert to string, trim spaces, and map values (`(+, -, 0)` → 0, `-` → -1, `0` → 0, `+` → 1).\n",
    "- **Phase:** Trim and map values (`A or O` → 0, `A` → 1, `O` → 2).\n",
    "- **Type** and **Shape:** Apply label encoding.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0cd51fc2-c574-4fdd-a091-6e3a63eec761",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique values in 'Char-ge': ['(+, -, 0)' '-' 0 '+']\n",
      "Unique values in 'Phase**,': ['A or O ' 'A' 'O']\n",
      "Unique values in 'Type': ['NaA zeolite' 'P-8Phenyl' 'P-1NH2' 'P-1NH3' 'P-8NH3Cl' 'P-8NH2' 'P-8NH3'\n",
      " 'P-8NH4' 'Carboxylic MWNT' 'Carbon Nanotubes with acidic group (CNTa)'\n",
      " 'Graphene Oxide (GO)' 'CNTa +GO (7:3)' 'Graphene oxide sheets'\n",
      " 'Graphene oxide' '\\ufeffMontmorillonite (MMT) Sodium Aluminium'\n",
      " '\\ufefflayered double hydroxide with magnesium/aluminium cations' 'TiO2'\n",
      " 'GO' 'rGO/TiO2' 'rGO/TiO3' 'rGO/TiO4' 'rGO/TiO5' 'rGO/TiO6'\n",
      " '\\ufeffhydrophobic zeolitic imidazolate framework-8'\n",
      " '\\ufeffhydrophobic zeolitic imidazolate framework-9'\n",
      " '\\ufeffhydrophobic zeolitic imidazolate framework-10'\n",
      " '\\ufeffhydrophobic zeolitic imidazolate framework-11'\n",
      " 'Non-porous spherical Silica NP' 'MCM-41 silica (Porous)' 'MIL-101 (Cr)'\n",
      " 'Amine functionalized CNT' 'Linde Type A zeolite' 'Silicon dioxide'\n",
      " 'MCM 48' 'MCM 49' 'MCM 50' 'MCM 51' 'MCM 52' 'MCM 53' 'MCM 54' 'MCM 55'\n",
      " 'MCM 56' 'MCM 57' 'carbon dots' 'Linde type A crystals'\n",
      " 'Graphene oxide with tannic acid' 'Nanosilver' 'EMT type zeolite (TMA)'\n",
      " 'aminated TMA' 'Polyamide/nitrogen-doped graphene oxide quantum dots'\n",
      " 'Halloysite nanotubes (HNT)' 'silicate-1 nanozeolite-PVA composite'\n",
      " 'NaA zeolite-PVA composite' 'Titanate nanotubes' 'NaX zeolite'\n",
      " 'NaY zeolite' 'aluminosilicate SWNT' 'NaA zeolite in Psf & PA'\n",
      " 'Cerium Oxide' 'Cellulose Nanocrystals']\n",
      "Unique values in 'Shape': ['Spherical' 'tubular' 'sheet' 'sheet+particle']\n",
      "\n",
      "Transformed Categorical Columns:\n",
      "   Type  Shape  Char-ge  Phase**,\n",
      "0    27      0        0         0\n",
      "1    27      0       -1         1\n",
      "2    27      0       -1         1\n",
      "3    27      0       -1         1\n",
      "4    27      0       -1         1\n"
     ]
    }
   ],
   "source": [
    "# Step 8: Encode Categorical Variables\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# First, let's inspect unique values for the categorical columns:\n",
    "print(\"Unique values in 'Char-ge':\", df['Char-ge'].unique())\n",
    "print(\"Unique values in 'Phase**,':\", df['Phase**,'].unique())\n",
    "print(\"Unique values in 'Type':\", df['Type'].unique())\n",
    "print(\"Unique values in 'Shape':\", df['Shape'].unique())\n",
    "\n",
    "# Convert 'Char-ge' and 'Phase**,'\n",
    "df['Char-ge'] = df['Char-ge'].astype(str).str.strip()\n",
    "df['Phase**,'] = df['Phase**,'].astype(str).str.strip()\n",
    "\n",
    "# Map 'Char-ge' to numeric values\n",
    "charge_map = {\n",
    "    '(+, -, 0)': 0,\n",
    "    '-': -1,\n",
    "    '0': 0,\n",
    "    '+': 1\n",
    "}\n",
    "df['Char-ge'] = df['Char-ge'].map(charge_map)\n",
    "\n",
    "# Map 'Phase**,'\n",
    "phase_map = {\n",
    "    'A or O': 0,\n",
    "    'A': 1,\n",
    "    'O': 2\n",
    "}\n",
    "df['Phase**,'] = df['Phase**,'].map(phase_map)\n",
    "\n",
    "# For 'Type' and 'Shape', we'll use label encoding (if they're not numeric already)\n",
    "le = LabelEncoder()\n",
    "df['Type'] = le.fit_transform(df['Type'])\n",
    "df['Shape'] = le.fit_transform(df['Shape'])\n",
    "\n",
    "# Verify the transformations:\n",
    "print(\"\\nTransformed Categorical Columns:\")\n",
    "print(df[['Type', 'Shape', 'Char-ge', 'Phase**,']].head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d73a86b5-508f-40be-bc06-e5c818957b0f",
   "metadata": {},
   "source": [
    "# Step 9: Separate Features and Targets\n",
    "\n",
    "**Description:**  \n",
    "Separate the dataset into a feature matrix **X** (all columns except **CWP** and **CSP**) and target vectors for **CWP** and **CSP**.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ccced2fe-b431-409a-88f7-b3670fa1dc78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features (X) shape: (189, 12)\n",
      "CWP (target) shape: (189,)\n",
      "CSP (target) shape: (189,)\n"
     ]
    }
   ],
   "source": [
    "# Step 9: Separate Features and Target Variables\n",
    "X = df.drop(columns=['CWP', 'CSP'])\n",
    "y_cwp = df['CWP']\n",
    "y_csp = df['CSP']\n",
    "\n",
    "# Print the shapes to confirm\n",
    "print(\"Features (X) shape:\", X.shape)\n",
    "print(\"CWP (target) shape:\", y_cwp.shape)\n",
    "print(\"CSP (target) shape:\", y_csp.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ba635ec-198d-42d5-ba41-08ae26f4dbcd",
   "metadata": {},
   "source": [
    " # Step 10: Train-Test Split for CWP\n",
    "\n",
    "**Description:**  \n",
    "Split the data for **CWP** prediction into an 80/20 training/testing split.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b22e0557-a2e3-4daf-8b72-73a372715887",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CWP Split:\n",
      "X_train_cwp shape: (151, 12)\n",
      "X_test_cwp shape: (38, 12)\n",
      "y_train_cwp shape: (151,)\n",
      "y_test_cwp shape: (38,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split data for CWP prediction\n",
    "X_train_cwp, X_test_cwp, y_train_cwp, y_test_cwp = train_test_split(X, y_cwp, test_size=0.2, random_state=42)\n",
    "\n",
    "# Print the shapes to confirm the split\n",
    "print(\"CWP Split:\")\n",
    "print(\"X_train_cwp shape:\", X_train_cwp.shape)\n",
    "print(\"X_test_cwp shape:\", X_test_cwp.shape)\n",
    "print(\"y_train_cwp shape:\", y_train_cwp.shape)\n",
    "print(\"y_test_cwp shape:\", y_test_cwp.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25479843-3b78-4791-ac9b-badaa8b6cf20",
   "metadata": {},
   "source": [
    "# Step 11: Feature Scaling for CWP\n",
    "\n",
    "**Description:**  \n",
    "Scale the training and test feature sets for CWP using StandardScaler.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c35c430a-b646-4c5a-8e8b-c3cb806c5a07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scaled X_train_cwp shape: (151, 12)\n",
      "Scaled X_test_cwp shape: (38, 12)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Initialize the scaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit and transform the training features, and transform the test features\n",
    "X_train_cwp_scaled = scaler.fit_transform(X_train_cwp)\n",
    "X_test_cwp_scaled = scaler.transform(X_test_cwp)\n",
    "\n",
    "# Print shapes to confirm\n",
    "print(\"Scaled X_train_cwp shape:\", X_train_cwp_scaled.shape)\n",
    "print(\"Scaled X_test_cwp shape:\", X_test_cwp_scaled.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23d8faca-5687-4c9a-9221-32dd36cb5376",
   "metadata": {},
   "source": [
    " # Step 12: Train a Linear Regression Model for CWP\n",
    "\n",
    "**Description:**  \n",
    "Train a baseline Linear Regression model on the scaled CWP training data and evaluate on the test set.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "4e9e0860-d473-4bd7-a7b3-6eacb0f9f7f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression for CWP - MSE: 0.5085, R2: 0.3029\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Initialize the Linear Regression model\n",
    "lr_cwp = LinearRegression()\n",
    "\n",
    "# Train the model on the scaled training data\n",
    "lr_cwp.fit(X_train_cwp_scaled, y_train_cwp)\n",
    "\n",
    "# Predict on the scaled test data\n",
    "y_pred_cwp_lr = lr_cwp.predict(X_test_cwp_scaled)\n",
    "\n",
    "# Evaluate the model performance\n",
    "mse_cwp_lr = mean_squared_error(y_test_cwp, y_pred_cwp_lr)\n",
    "r2_cwp_lr = r2_score(y_test_cwp, y_pred_cwp_lr)\n",
    "\n",
    "print(f\"Linear Regression for CWP - MSE: {mse_cwp_lr:.4f}, R2: {r2_cwp_lr:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e69bef5c-765d-42da-a9d1-9dedf7fbb4a8",
   "metadata": {},
   "source": [
    " # Step 13: Train a Random Forest Model for CWP\n",
    "\n",
    "**Description:**  \n",
    "Train a Random Forest Regressor on the scaled CWP training data and evaluate its performance on the test set.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "29b6068c-2156-403d-9870-84ef6b1ee93e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest for CWP - MSE: 0.4574, R2: 0.3729\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# Initialize the Random Forest model\n",
    "rf_cwp = RandomForestRegressor(n_estimators=200, random_state=42)\n",
    "\n",
    "# Train the model on the scaled training data\n",
    "rf_cwp.fit(X_train_cwp_scaled, y_train_cwp)\n",
    "\n",
    "# Predict on the scaled test data\n",
    "y_pred_cwp_rf = rf_cwp.predict(X_test_cwp_scaled)\n",
    "\n",
    "# Evaluate the model performance\n",
    "mse_cwp_rf = mean_squared_error(y_test_cwp, y_pred_cwp_rf)\n",
    "r2_cwp_rf = r2_score(y_test_cwp, y_pred_cwp_rf)\n",
    "\n",
    "print(f\"Random Forest for CWP - MSE: {mse_cwp_rf:.4f}, R2: {r2_cwp_rf:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7505b88b-2d66-4118-8224-42fa9e56bb69",
   "metadata": {},
   "source": [
    " # Step 14: Hyperparameter Tuning for CWP Using GridSearchCV\n",
    "\n",
    "**Description:**  \n",
    "Perform hyperparameter tuning on the Random Forest model for CWP using GridSearchCV.  \n",
    "Tuning parameters include `n_estimators`, `max_depth`, `max_features`, `min_samples_split`, and `min_samples_leaf`.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "22893962-6bb6-47fc-886a-8789ccdc6a7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 72 candidates, totalling 360 fits\n",
      "Best parameters for CWP: {'max_depth': None, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 100}\n",
      "Tuned RF for CWP - MSE: 0.4191, R2: 0.4254\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# Define a parameter grid for tuning\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [None, 10, 20],\n",
    "    'max_features': ['sqrt', 'log2'],\n",
    "    'min_samples_split': [2, 5],\n",
    "    'min_samples_leaf': [1, 2]\n",
    "}\n",
    "\n",
    "# Initialize the Random Forest model\n",
    "rf_model = RandomForestRegressor(random_state=42)\n",
    "\n",
    "# Setup GridSearchCV\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=rf_model,\n",
    "    param_grid=param_grid,\n",
    "    cv=5,\n",
    "    scoring='neg_mean_squared_error',\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Fit GridSearchCV on the scaled training data for CWP\n",
    "grid_search.fit(X_train_cwp_scaled, y_train_cwp)\n",
    "\n",
    "# Print best parameters\n",
    "print(\"Best parameters for CWP:\", grid_search.best_params_)\n",
    "\n",
    "# Evaluate the tuned model on the test set\n",
    "best_rf_cwp = grid_search.best_estimator_\n",
    "y_pred_tuned_cwp = best_rf_cwp.predict(X_test_cwp_scaled)\n",
    "mse_tuned_cwp = mean_squared_error(y_test_cwp, y_pred_tuned_cwp)\n",
    "r2_tuned_cwp = r2_score(y_test_cwp, y_pred_tuned_cwp)\n",
    "\n",
    "print(f\"Tuned RF for CWP - MSE: {mse_tuned_cwp:.4f}, R2: {r2_tuned_cwp:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "122ec153-7362-4d08-ac43-11a9e38436c6",
   "metadata": {},
   "source": [
    " # Step 15: Train-Test Split for CSP\n",
    "\n",
    "**Description:**  \n",
    "Split the dataset for **CSP** prediction (80/20 split).\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "38d41138-0018-4563-9c5c-63268b5cfec4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSP Split:\n",
      "X_train_csp shape: (151, 12)\n",
      "X_test_csp shape: (38, 12)\n",
      "y_train_csp shape: (151,)\n",
      "y_test_csp shape: (38,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# For CSP prediction, separate features and target\n",
    "X_csp = df.drop(columns=['CWP', 'CSP'])\n",
    "y_csp = df['CSP']\n",
    "\n",
    "# Split the data (80% train, 20% test) for CSP\n",
    "X_train_csp, X_test_csp, y_train_csp, y_test_csp = train_test_split(X_csp, y_csp, test_size=0.2, random_state=42)\n",
    "\n",
    "# Print the shapes to confirm the split\n",
    "print(\"CSP Split:\")\n",
    "print(\"X_train_csp shape:\", X_train_csp.shape)\n",
    "print(\"X_test_csp shape:\", X_test_csp.shape)\n",
    "print(\"y_train_csp shape:\", y_train_csp.shape)\n",
    "print(\"y_test_csp shape:\", y_test_csp.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a7bed7b-adb7-4a5e-892c-08eb1ec0abe0",
   "metadata": {},
   "source": [
    "# Step 16: Feature Scaling for CSP\n",
    "\n",
    "**Description:**  \n",
    "Scale the CSP training and test features using StandardScaler.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "a61f55ca-a016-4306-8ce0-b96cbc85f2fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scaled X_train_csp shape: (151, 12)\n",
      "Scaled X_test_csp shape: (38, 12)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Step 16: Feature Scaling for CSP\n",
    "scaler_csp = StandardScaler()\n",
    "X_train_csp_scaled = scaler_csp.fit_transform(X_train_csp)\n",
    "X_test_csp_scaled = scaler_csp.transform(X_test_csp)\n",
    "\n",
    "print(\"Scaled X_train_csp shape:\", X_train_csp_scaled.shape)\n",
    "print(\"Scaled X_test_csp shape:\", X_test_csp_scaled.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "398cf7ac-890f-420a-94bf-a10152182b27",
   "metadata": {},
   "source": [
    "# Step 17: Train a Linear Regression Model for CSP\n",
    "\n",
    "**Description:**  \n",
    "Train a baseline Linear Regression model for CSP using the scaled data and evaluate its performance.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "68c93947-d7d8-4892-a16d-1444eeaa3b54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression for CSP - MSE: 3.3799, R2: 0.3187\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Initialize the Linear Regression model for CSP\n",
    "lr_csp = LinearRegression()\n",
    "\n",
    "# Train the model on the scaled CSP training data\n",
    "lr_csp.fit(X_train_csp_scaled, y_train_csp)\n",
    "\n",
    "# Predict on the scaled CSP test data\n",
    "y_pred_csp_lr = lr_csp.predict(X_test_csp_scaled)\n",
    "\n",
    "# Evaluate model performance\n",
    "mse_csp_lr = mean_squared_error(y_test_csp, y_pred_csp_lr)\n",
    "r2_csp_lr = r2_score(y_test_csp, y_pred_csp_lr)\n",
    "\n",
    "print(f\"Linear Regression for CSP - MSE: {mse_csp_lr:.4f}, R2: {r2_csp_lr:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9b70ffd-e927-4740-b3e5-cffa3a070e10",
   "metadata": {},
   "source": [
    "# Step 18: Train a Random Forest Model for CSP\n",
    "\n",
    "**Description:**  \n",
    "Train a Random Forest Regressor for CSP using the scaled training data and evaluate on the test set.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "2c410e5c-1967-4776-8b87-236c99dd94dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest for CSP - MSE: 0.7099, R2: 0.8569\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# Initialize the Random Forest model for CSP\n",
    "rf_csp = RandomForestRegressor(n_estimators=200, random_state=42)\n",
    "\n",
    "# Train the model on the scaled CSP training data\n",
    "rf_csp.fit(X_train_csp_scaled, y_train_csp)\n",
    "\n",
    "# Predict on the scaled CSP test data\n",
    "y_pred_csp_rf = rf_csp.predict(X_test_csp_scaled)\n",
    "\n",
    "# Evaluate model performance\n",
    "mse_csp_rf = mean_squared_error(y_test_csp, y_pred_csp_rf)\n",
    "r2_csp_rf = r2_score(y_test_csp, y_pred_csp_rf)\n",
    "\n",
    "print(f\"Random Forest for CSP - MSE: {mse_csp_rf:.4f}, R2: {r2_csp_rf:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bc2e861-8a4a-4183-b906-b39a81d22b90",
   "metadata": {},
   "source": [
    "# Step 19: Hyperparameter Tuning for CSP Using GridSearchCV\n",
    "\n",
    "**Description:**  \n",
    "Perform hyperparameter tuning for the CSP Random Forest model using GridSearchCV.  \n",
    "Tuning parameters include `n_estimators`, `max_depth`, `max_features`, `min_samples_split`, and `min_samples_leaf`.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "e5ae261e-3936-48cc-a112-f3f23e2c6d5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 72 candidates, totalling 360 fits\n",
      "Best Parameters for CSP: {'max_depth': None, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 300}\n",
      "Tuned RF for CSP - MSE: 0.8408, R2: 0.8305\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# Define the parameter grid for CSP tuning\n",
    "param_grid_csp = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [None, 10, 20],\n",
    "    'max_features': ['sqrt', 'log2'],\n",
    "    'min_samples_split': [2, 5],\n",
    "    'min_samples_leaf': [1, 2]\n",
    "}\n",
    "\n",
    "# Initialize the Random Forest model\n",
    "rf_csp_model = RandomForestRegressor(random_state=42)\n",
    "\n",
    "# Setup GridSearchCV\n",
    "grid_search_csp = GridSearchCV(\n",
    "    estimator=rf_csp_model,\n",
    "    param_grid=param_grid_csp,\n",
    "    cv=5,\n",
    "    scoring='neg_mean_squared_error',\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Fit GridSearchCV on the scaled training data for CSP\n",
    "grid_search_csp.fit(X_train_csp_scaled, y_train_csp)\n",
    "\n",
    "# Print the best parameters\n",
    "print(\"Best Parameters for CSP:\", grid_search_csp.best_params_)\n",
    "\n",
    "# Evaluate the tuned model on the test set\n",
    "best_rf_csp = grid_search_csp.best_estimator_\n",
    "y_pred_tuned_csp = best_rf_csp.predict(X_test_csp_scaled)\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "mse_tuned_csp = mean_squared_error(y_test_csp, y_pred_tuned_csp)\n",
    "r2_tuned_csp = r2_score(y_test_csp, y_pred_tuned_csp)\n",
    "\n",
    "print(f\"Tuned RF for CSP - MSE: {mse_tuned_csp:.4f}, R2: {r2_tuned_csp:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "2e25a790-3a8e-4cbe-a85b-cd31f2601382",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best RF model for CWP saved as 'best_rf_cwp_model.pkl'\n",
      "Best RF model for CSP saved as 'best_rf_csp_model.pkl'\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "# Save the best Random Forest model for CWP\n",
    "joblib.dump(best_rf_cwp, \"best_rf_cwp_model.pkl\")\n",
    "print(\"Best RF model for CWP saved as 'best_rf_cwp_model.pkl'\")\n",
    "\n",
    "# Save the best Random Forest model for CSP\n",
    "joblib.dump(best_rf_csp, \"best_rf_csp_model.pkl\")\n",
    "print(\"Best RF model for CSP saved as 'best_rf_csp_model.pkl'\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90b1182a-a317-4a8d-b060-bf3b9ae4a0c2",
   "metadata": {},
   "source": [
    " Load the models\n",
    "loaded_rf_cwp = joblib.load(\"best_rf_cwp_model.pkl\")\n",
    "loaded_rf_csp = joblib.load(\"best_rf_csp_model.pkl\")\n",
    "\n",
    " Example: Predict on new data (replace X_new with your data)\n",
    " y_pred_cwp = loaded_rf_cwp.predict(X_new_scaled_for_cwp)\n",
    " y_pred_csp = loaded_rf_csp.predict(X_new_scaled_for_csp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44b1dbf6-d35b-4188-9d4a-a33ce3913477",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
